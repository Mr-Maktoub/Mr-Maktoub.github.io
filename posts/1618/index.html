<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>信息熵 | 马克图布</title><meta name="author" content="马克图布"><meta name="copyright" content="马克图布"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本文地址，转载自LR-bee 详细可内容可点击下面参考文章 参考1 参考2 一、自信息自信息：可以理解表示某一事件发生时所带来的信息量的多少，当事件发生的概率越大，则自信息越小，或者可以这样理解：某一事件发生的概率非常小，但是实际上却发生了(观察结果)，则此时的自信息非常大；某一事件发生的概率非常大，并且实际上也发生了，则此时的自信息较小。 数学公式：   函数所对应的图像表示 其中 P 表示随机">
<meta property="og:type" content="article">
<meta property="og:title" content="信息熵">
<meta property="og:url" content="https://mr-maktoub.github.io/posts/1618/index.html">
<meta property="og:site_name" content="马克图布">
<meta property="og:description" content="本文地址，转载自LR-bee 详细可内容可点击下面参考文章 参考1 参考2 一、自信息自信息：可以理解表示某一事件发生时所带来的信息量的多少，当事件发生的概率越大，则自信息越小，或者可以这样理解：某一事件发生的概率非常小，但是实际上却发生了(观察结果)，则此时的自信息非常大；某一事件发生的概率非常大，并且实际上也发生了，则此时的自信息较小。 数学公式：   函数所对应的图像表示 其中 P 表示随机">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mr-maktoub.github.io/img/avatar1.png">
<meta property="article:published_time" content="2023-01-01T08:12:20.000Z">
<meta property="article:modified_time" content="2023-05-09T03:23:32.499Z">
<meta property="article:author" content="马克图布">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mr-maktoub.github.io/img/avatar1.png"><link rel="shortcut icon" href="/img/log3.jfif"><link rel="canonical" href="https://mr-maktoub.github.io/posts/1618/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '信息熵',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2023-05-09 11:23:32'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">66</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw iconfont icon-shouyex"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw iconfont icon-zuixinwenzhang_huaban"></i><span> 找文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw iconfont icon-fenlei1"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw iconfont icon-biaoqian1"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw iconfont icon-shijianzhou"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw iconfont icon-shenghuo"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/messageboard/"><i class="fa-fw iconfont icon-liaotian-04"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw iconfont icon-lianjie"></i><span> 友人帐</span></a></li><li><a class="site-page child" href="/share/"><i class="fa-fw iconfont icon-fenxiang"></i><span> 分享</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw iconfont icon-xiangce"></i><span> 相册</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw iconfont icon-shuji"></i><span> 书籍</span></a></li><li><a class="site-page child" href="/FilmAndTV/"><i class="fa-fw iconfont icon-yingshi1"></i><span> 影视</span></a></li><li><a class="site-page child" href="/daohang/"><i class="fa-fw iconfont icon-daohang"></i><span> 导航站</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw iconfont icon-gerenzhongxin"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/cover.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="马克图布"><img class="site-icon" src="/img/log3.jfif"/><span class="site-name">马克图布</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw iconfont icon-shouyex"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw iconfont icon-zuixinwenzhang_huaban"></i><span> 找文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw iconfont icon-fenlei1"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw iconfont icon-biaoqian1"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw iconfont icon-shijianzhou"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw iconfont icon-shenghuo"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/messageboard/"><i class="fa-fw iconfont icon-liaotian-04"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw iconfont icon-lianjie"></i><span> 友人帐</span></a></li><li><a class="site-page child" href="/share/"><i class="fa-fw iconfont icon-fenxiang"></i><span> 分享</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw iconfont icon-xiangce"></i><span> 相册</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw iconfont icon-shuji"></i><span> 书籍</span></a></li><li><a class="site-page child" href="/FilmAndTV/"><i class="fa-fw iconfont icon-yingshi1"></i><span> 影视</span></a></li><li><a class="site-page child" href="/daohang/"><i class="fa-fw iconfont icon-daohang"></i><span> 导航站</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw iconfont icon-gerenzhongxin"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">信息熵</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-01T08:12:20.000Z" title="发表于 2023-01-01 16:12:20">2023-01-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-09T03:23:32.499Z" title="更新于 2023-05-09 11:23:32">2023-05-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数学基础</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="信息熵"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/304499706">本文地址</a>，转载自<a target="_blank" rel="noopener" href="https://www.zhihu.com/people/nan-de-4-89">LR-bee</a></p>
<p>详细可内容可点击下面参考文章</p>
<p><a target="_blank" rel="noopener" href="https://www.dandelioncloud.cn/article/details/1532328936818372609">参考1</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yujianmin1990/article/details/71213601">参考2</a></p>
<h2 id="一、自信息"><a href="#一、自信息" class="headerlink" title="一、自信息"></a>一、自信息</h2><p>自信息：可以理解<strong>表示某一事件发生时所带来的信息量的多少</strong>，当事件发生的概率越大，则自信息越小，或者可以这样理解：某一事件发生的概率非常小，但是实际上却发生了(观察结果)，则此时的自信息非常大；某一事件发生的概率非常大，并且实际上也发生了，则此时的自信息较小。</p>
<p>数学公式：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011616162.png" alt="image-20230101161645137"></p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011613599.png" alt="image-20230101161335552"></p>
<p>函数所对应的图像表示</p>
<p>其中 <strong>P</strong> 表示随机变量的第i个事件发生的概率，自信息单位是bit,表征描述该信息需要多少位。可以看出，<strong>自信息的计算和随机变量本身数值没有关系，只和其概率有关</strong>，同时可以很容易发现上述定义满足自信息的3个条件。</p>
<p>自信息满足以下性质：</p>
<ol>
<li>连续性，即 I 随着 p 的变化连续变化。</li>
<li>单调递减性，即发生的概率越小，确定它发生所需要的信息量越大。</li>
<li>当 p→0 时， I→ ∞. 即确定不可能事件发生需要的信息量为无穷大。</li>
<li>当 p→1 时， I→0 . 即对确定一定会发生事件发生需要的信息量为0。</li>
<li>独立随机变量的自信息等于各自自信息的代数和。</li>
</ol>
<p>同样，我们可以定义联合分布：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011617277.png" alt="image-20230101161717253"></p>
<p>如果X与Y独立，则：    </p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011617696.png" alt="image-20230101161740669"></p>
<h2 id="二、信息熵-一种信息量平均值（期望）"><a href="#二、信息熵-一种信息量平均值（期望）" class="headerlink" title="二、信息熵 -一种信息量平均值（期望）"></a>二、信息熵 -一种信息量平均值（期望）</h2><p>上述自信息描述的是随机变量的某个事件发生所带来的信息量，而<strong>信息熵通常用来描述整个随机分布所带来的信息量平均值，更具统计特性</strong>。信息熵也叫香农熵，在机器学习中，由于熵的计算是依据样本数据而来，故也叫经验熵。其公式定义如下：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011616162.png" alt="image-20230101161645137"></p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011618505.png" alt="image-20230101161834474"></p>
<p>由上可知：</p>
<p>信息熵H(X)是各项自信息的累加值，由于每一项都是整正数，故而<strong>随机变量取值个数越多，状态数也就越多，累加次数就越多，信息熵就越大，混乱程度就越大，纯度越小</strong>。越宽广的分布，熵就越大，在同样的定义域内，熵的关系为脉冲分布信息熵&lt;高斯分布信息熵&lt;均匀分布信息熵。可以通过数学证明，当随机变量分布为均匀分布时即状态数最多时，熵最大。<strong>熵代表了随机分布的混乱程度</strong>。</p>
<p>同样推广至多维随机变量的联合分布，其联合信息熵为：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011619840.png" alt="image-20230101161916814"></p>
<p>说明：</p>
<ol>
<li>熵只依赖于随机变量的分布,与随机变量取值无关；</li>
<li>定义0log0=0(因为可能出现某个取值概率为0的情况)；</li>
<li>熵越大,随机变量的不确定性就越大,分布越混乱，随机变量状态数越多。</li>
</ol>
<h2 id="三、条件熵-信息熵-联合分布的-自信息-给定变量的自信息"><a href="#三、条件熵-信息熵-联合分布的-自信息-给定变量的自信息" class="headerlink" title="三、条件熵- 信息熵(联合分布的)-自信息(给定变量的自信息)"></a>三、条件熵- 信息熵(联合分布的)-自信息(给定变量的自信息)</h2><p>两个随机变量的关系，可以用交叉熵、相对熵、联合熵和互信息来描述。</p>
<p><strong>条件熵的定义为：在X给定条件下，Y的条件概率分布的熵对X的数学期望。</strong></p>
<p>与条件概率相对比之下，就可以很好的学习与理解了：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011619453.png" alt="image-20230101161948417"></p>
<p>根据联合熵的公式进行理解第二个等式</p>
<p>同理可得：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011620994.png" alt="image-20230101162021973"></p>
<h2 id="四、交叉熵-—一个分布的自信息对另一分布的期望"><a href="#四、交叉熵-—一个分布的自信息对另一分布的期望" class="headerlink" title="四、交叉熵 —一个分布的自信息对另一分布的期望"></a>四、交叉熵 —一个分布的自信息对另一分布的期望</h2><p>对交叉熵应该是最熟悉的，其广泛用在逻辑回归的Sigmoid和softmax函数中作为损失函数使用。其主要用于度量两个概率分布间的差异性信息。</p>
<p><strong>p对q的交叉熵表示q分布的自信息对p分布的期望</strong>，公式定义为：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621270.png" alt="image-20230101162107236"></p>
<p>其中。p是真实样本分布，q是预测得到样本分布。在信息论中，其计算的数值表示：如果用错误的编码方式q去编码真实分布p的事件，需要多少bit数，是一种非常有用的衡量概率分布相似性的数学工具。</p>
<p>由于交叉熵在逻辑回归中应用广泛，这里给出其定义式，使读者知道交叉熵的具体应用。逻辑回归算法的损失函数就是交叉熵，也叫做负对数似然，其定义为：(sigmoid函数形式下)</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621072.png" alt="image-20230101162119047"></p>
<p>其中，yi是第i个样本的真实标签，h是sigmoid预测输出值，J是凸函数，可以得到全局最优解。</p>
<p>针<strong>对于多分类的逻辑回归算法，通常使用Softmax作为输出层映射</strong>，其对应的损失函数也叫交叉熵，只不过写法有点区别，具体如下：(softmax函数下)</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621484.png" alt="image-20230101162128448"></p>
<p>其中，m是样本个数，k是输出层个数。</p>
<p>二者进行对比：可以得出，二者是相一致的</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621194.png" alt="image-20230101162143148"></p>
<h3 id="交叉熵在逻辑分类问题中的应用："><a href="#交叉熵在逻辑分类问题中的应用：" class="headerlink" title="交叉熵在逻辑分类问题中的应用："></a>交叉熵在逻辑分类问题中的应用：</h3><h3 id="单分类问题中："><a href="#单分类问题中：" class="headerlink" title="单分类问题中："></a>单分类问题中：</h3><p>sigmoid函数形式下：</p>
<p>这里的单类别是指，每一张图像样本只能有一个类别，比如只能是狗或只能是猫。<br>交叉熵在单分类问题上基本是标配的方法</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011621948.png" alt="image-20230101162154923"></p>
<p>上式为一张样本的loss计算方法。式2.1中n代表着n种类别。<br>举例说明,比如有如下样本</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622853.png" alt="image-20230101162207811"></p>
<h3 id="多分类问题中："><a href="#多分类问题中：" class="headerlink" title="多分类问题中："></a>多分类问题中：</h3><p>这里的多类别是指，每一张图像样本可以有多个类别，比如同时包含一只猫和一只狗<br>和单分类问题的标签不同，多分类的标签是n-hot。<br>比如下面这张样本图，即有青蛙，又有老鼠，所以是一个多分类问题</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622879.png" alt="image-20230101162218847"></p>
<p>值得注意的是，这里的Pred不再是通过softmax计算的了，这里采用的是sigmoid。将每一个节点的输出归一化到[0,1]之间。所有Pred值的和也不再为1。换句话说，<strong>就是每一个Label都是独立分布的，相互之间没有影响。所以交叉熵在这里是单独对每一个节点进行计算，每一个节点只有两种可能值，所以是一个二项分布。</strong>前面说过对于二项分布这种特殊的分布，熵的计算可以进行简化。</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622625.png" alt="image-20230101162230577"></p>
<p>softmax函数下：输出层映射</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011622947.png" alt="image-20230101162241897"></p>
<p>通过输入一个向量，通过softmax公式映射得到一个概率向量，最后将其分到算出概率最大的一类。</p>
<p><strong>补充：交叉熵和最大似然的loss函数是一致的</strong></p>
<h2 id="五、相对熵"><a href="#五、相对熵" class="headerlink" title="五、相对熵"></a>五、相对熵</h2><p>相对熵经常也叫做KL散度，在贝叶斯推理中，</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623173.png" alt="image-20230101162303151"></p>
<p>衡量当你修改了从先验分布 q 到后验分布 p 的信息之后带来的信息增益。首先给出其公式：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623932.png" alt="image-20230101162313892"></p>
<p>后一部分就是p的熵，而前一部分就是交叉熵。故又回到：</p>
<p>在机器学习中，我们需要评估label和predicts之间的差距，使用KL散度刚刚好，即<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="9.808ex" height="2.398ex" role="img" focusable="false" viewBox="0 -810 4335.2 1060"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="TeXAtom" transform="translate(861,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(889,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2021.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2410.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2900.2,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(3178.2,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3456.2,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3946.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>，由于KL散度中的前一部分−<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.878ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2156 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(888,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1277,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1767,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>不变，故在优化过程中，只需要关注交叉熵就可以了。所以一般在机器学习中直接用用交叉熵做loss，评估模型。</p>
<p>相对熵较交叉熵有更多的优异性质，主要为：</p>
<ol>
<li>当p分布和q分布相等时候，KL散度值为0，这是一个非常好的性质；</li>
<li>可以证明是非负的；</li>
<li>非对称的，通过公式可以看出，KL散度是衡量两个分布的不相似性，不相似性越大，则值越大，当完全相同时，取值为0。</li>
</ol>
<p>简单对比交叉熵和相对熵，可以发现仅仅差了一个H(p)，如果从优化角度来看，p是真实分布，是固定值，最小化KL散度情况下，H(p)可以省略，此时交叉熵等价于KL散度(相对熵)。</p>
<p>简单对比交叉熵和相对熵，可以发现仅仅差了一个H(p)，如果从优化角度来看，p是真实分布，是固定值，最小化KL散度情况下，H(p)可以省略，此时交叉熵等价于KL散度。</p>
<p>下面讨论一个比较现实且非常重要的问题：既然相对熵和交叉熵表示的含义一样，为啥需要两个？在机器学习中何时使用相对熵，何时使用交叉熵？要彻底说清这个问题，难度很大，这里我仅仅从我知道的方面讲讲。首先需要明确：<strong>在最优化问题中，最小化相对熵等价于最小化交叉熵；相对熵和交叉熵的定义其实都可以从最大似然估计得到</strong>，详细推导：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623902.png" alt="image-20230101162330850"></p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623299.png" alt="image-20230101162338250"></p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011623508.png" alt="image-20230101162355414"></p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624218.png" alt="image-20230101162408187"></p>
<p>我们都明白：</p>
<p>交叉熵大量应用在Sigmoid函数和SoftMax函数中，最典型的算法应该就是神经网络和逻辑回归吧，而相对熵大量应用在生成模型中，例如GAN、EM、贝叶斯学习和变分推导中。从这里我们可以看出一些端倪，如果想通过算法对样本数据进行概率分布建模，那么通常都是使用相对熵，因为我们需要明确的知道生成的分布和真实分布的差距，最好的KL散度值应该是0；而在判别模型中，仅仅只需要评估损失函数的下降值即可，交叉熵可以满足要求，其计算量比KL散度小。</p>
<p><em>数学之美</em>书中，有这样几句话：交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小，相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异。</p>
<h2 id="六、互信息"><a href="#六、互信息" class="headerlink" title="六、互信息"></a>六、互信息</h2><p>互信息在信息论和机器学习中非常重要，其可以评价两个分布之间的距离，这主要归因于其对称性，假设互信息不具备对称性，那么就不能作为距离度量。即相对熵，由于不满足对称性，故通常说相对熵是评价分布的相似程度，而不会说距离。</p>
<p>对于p(x,y)，给出两个变量组成的数据集。若两变量相互独立，那么p(x,y)=p(x)p(y)，若两变量不独立，那么我们要考察联合概率分布和边缘概率分布的KL散度，以判断两者是否接近独立。</p>
<p>互信息的定义：<strong>一个随机变量由于已知另一个随机变量而减少的不确定性</strong>，或者说从贝叶斯角度考虑，由于新的观测数据y到来而导致x分布的不确定性下降程度。</p>
<p>数学公式：</p>
<p>第一步的推导：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624683.png" alt="image-20230101162429633"></p>
<p>第二三步的推导：</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624320.png" alt="image-20230101162440288"></p>
<p>从公式中可以看出互信息是满足对称性的，<strong>其在特性选择、分布的距离评估中应用非常广泛，请务必掌握</strong>。其实互信息和相对熵也存在联系，如果说相对熵不能作为距离度量，是因为其非对称性，那么互信息的出现正好弥补了该缺陷，使得我们可以计算任意两个随机变量之间的距离，或者说两个随机变量分布之间的相关性、独立性。</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011624931.png" alt="image-20230101162450906"></p>
<p>信息也是大于等于0的，当且仅当x与y相互独立时候取等号。</p>
<p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011625418.png" alt="image-20230101162501349"></p>
<h2 id="最后：自信息、互信息、条件熵等各种熵的关系示意图："><a href="#最后：自信息、互信息、条件熵等各种熵的关系示意图：" class="headerlink" title="最后：自信息、互信息、条件熵等各种熵的关系示意图："></a>最后：自信息、互信息、条件熵等各种熵的关系示意图：</h2><p><img src="https://raw.githubusercontent.com/RisingAuroras/giteePagesImgs/master/202301011625618.png" alt="image-20230101162516560"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://mr-maktoub.github.io">马克图布</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://mr-maktoub.github.io/posts/1618/">https://mr-maktoub.github.io/posts/1618/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://mr-maktoub.github.io" target="_blank">马克图布</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/avatar1.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/7280/" title="What is Mutual Information?"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">What is Mutual Information?</div></div></a></div><div class="next-post pull-right"><a href="/posts/bf25/" title="论文储备知识"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">论文储备知识</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar1.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">马克图布</div><div class="author-info__description">记录我的遗忘</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">66</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%87%AA%E4%BF%A1%E6%81%AF"><span class="toc-number">1.</span> <span class="toc-text">一、自信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%BF%A1%E6%81%AF%E7%86%B5-%E4%B8%80%E7%A7%8D%E4%BF%A1%E6%81%AF%E9%87%8F%E5%B9%B3%E5%9D%87%E5%80%BC%EF%BC%88%E6%9C%9F%E6%9C%9B%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">二、信息熵 -一种信息量平均值（期望）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%9D%A1%E4%BB%B6%E7%86%B5-%E4%BF%A1%E6%81%AF%E7%86%B5-%E8%81%94%E5%90%88%E5%88%86%E5%B8%83%E7%9A%84-%E8%87%AA%E4%BF%A1%E6%81%AF-%E7%BB%99%E5%AE%9A%E5%8F%98%E9%87%8F%E7%9A%84%E8%87%AA%E4%BF%A1%E6%81%AF"><span class="toc-number">3.</span> <span class="toc-text">三、条件熵- 信息熵(联合分布的)-自信息(给定变量的自信息)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E4%BA%A4%E5%8F%89%E7%86%B5-%E2%80%94%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E7%9A%84%E8%87%AA%E4%BF%A1%E6%81%AF%E5%AF%B9%E5%8F%A6%E4%B8%80%E5%88%86%E5%B8%83%E7%9A%84%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.</span> <span class="toc-text">四、交叉熵 —一个分布的自信息对另一分布的期望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5%E5%9C%A8%E9%80%BB%E8%BE%91%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%EF%BC%9A"><span class="toc-number">4.1.</span> <span class="toc-text">交叉熵在逻辑分类问题中的应用：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E4%B8%AD%EF%BC%9A"><span class="toc-number">4.2.</span> <span class="toc-text">单分类问题中：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E4%B8%AD%EF%BC%9A"><span class="toc-number">4.3.</span> <span class="toc-text">多分类问题中：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E7%9B%B8%E5%AF%B9%E7%86%B5"><span class="toc-number">5.</span> <span class="toc-text">五、相对熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E4%BA%92%E4%BF%A1%E6%81%AF"><span class="toc-number">6.</span> <span class="toc-text">六、互信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%90%8E%EF%BC%9A%E8%87%AA%E4%BF%A1%E6%81%AF%E3%80%81%E4%BA%92%E4%BF%A1%E6%81%AF%E3%80%81%E6%9D%A1%E4%BB%B6%E7%86%B5%E7%AD%89%E5%90%84%E7%A7%8D%E7%86%B5%E7%9A%84%E5%85%B3%E7%B3%BB%E7%A4%BA%E6%84%8F%E5%9B%BE%EF%BC%9A"><span class="toc-number">7.</span> <span class="toc-text">最后：自信息、互信息、条件熵等各种熵的关系示意图：</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/3eeb/" title="Hello World">Hello World</a><time datetime="2023-06-01T07:29:35.968Z" title="发表于 2023-06-01 15:29:35">2023-06-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/6f25/" title="我的云音乐APP开发课程笔记">我的云音乐APP开发课程笔记</a><time datetime="2023-06-01T07:29:35.962Z" title="发表于 2023-06-01 15:29:35">2023-06-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/8462/" title="重新梳理Android权限管理">重新梳理Android权限管理</a><time datetime="2023-06-01T07:29:35.959Z" title="发表于 2023-06-01 15:29:35">2023-06-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/9958/" title="《吴恩达机器学习笔记》">《吴恩达机器学习笔记》</a><time datetime="2023-06-01T07:29:35.949Z" title="发表于 2023-06-01 15:29:35">2023-06-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/935d/" title="常见不等式、等式与基础理论">常见不等式、等式与基础理论</a><time datetime="2023-06-01T07:29:35.914Z" title="发表于 2023-06-01 15:29:35">2023-06-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 马克图布</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>